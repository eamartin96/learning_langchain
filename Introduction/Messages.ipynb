{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c0cda2-79eb-4197-be36-d53f95650f90",
   "metadata": {},
   "source": [
    "# LangChain Messages\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM\n",
    "\n",
    "Messages are objects that contain:\n",
    "- **Role** - Identifies the message tpye (e.g. **system**, **user**)\n",
    "- **Content** - Represents the actual content of the message (like text, images, audio, documents, etc.)\n",
    "- **Metadata**: Optional fields such as response information, message IDs, and token usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef29b3c-e725-48c6-a42b-ce7951f7a83a",
   "metadata": {},
   "source": [
    "## Load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7466e09e-8d16-47b3-9e83-c0abc4218e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21030528-ed1e-49fb-b29b-b3286e6e67a5",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "051a420f-65ba-4d24-91f8-2bc74ee0e287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! As an artificial intelligence, I don't have feelings, but I'm here and ready to assist you. How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 23, 'total_tokens': 53, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CjR5Yk2q8mQMnOdEz8Z5Fy4eCEdej', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d399088e-ea66-4b85-84e5-351991fc3bec-0', usage_metadata={'input_tokens': 23, 'output_tokens': 30, 'total_tokens': 53, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "model = init_chat_model(\"gpt-4\")\n",
    "\n",
    "system_msg = SystemMessage(\"You are a helpful assistant.\")\n",
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "# Use with chat models\n",
    "messages = [system_msg, human_msg]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7c87c-70dd-4dbe-8a45-71911a84d5fa",
   "metadata": {},
   "source": [
    "### Text prompts\n",
    "Text prompts are strings - ideal for straightforward generation tasks where you don't need to retain conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d6471-f43a-4940-a7ce-06c56a8bae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"Write a haiku about spring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b404d-2c37-41f5-9ede-176abf82fb87",
   "metadata": {},
   "source": [
    "### Message prompts\n",
    "Alternatively, you can pass in a list of messages to the model by providing a list of message objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57869a-a3b6-47ca-a4f8-62b75c501376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a poetry expert\"),\n",
    "    HumanMessage(\"Write a haiku about spring\"),\n",
    "    AIMessage(\"Cherry blossoms bloom...\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1277a62-3d99-4d69-bc21-b934365dd9c4",
   "metadata": {},
   "source": [
    "### Dictionary format\n",
    "You can also specify messages firectly in OpenAI chat completions format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025997e0-3b13-4a40-b5ea-4691052371e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetry expert\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about spring\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cherry blossoms bloom...\"}\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad6326-4ec0-4b11-992a-df6ff7faf1e9",
   "metadata": {},
   "source": [
    "## Message types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd3cf0-2fc8-4458-b9d3-ba279a970ab3",
   "metadata": {},
   "source": [
    "### SystemMessage\n",
    "A SystemMessage represent an initial set of instructions that primes the model's behavior. You can use a system message to set the tone, define the model's role, and establish guidelines for responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734cf608-83ba-4ce1-9f53-84039e3fa6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = SystemMessage(\"You are a helpful coding assistant.\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3eb9ba-775d-48f4-a2e8-7d1c1872330c",
   "metadata": {},
   "source": [
    "### HumanMessage\n",
    "A HumanMessage represents user input and interactions. They can contain text, images, audio, files, and any other amount of multimodal content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78bbe6-267e-41b3-a960-05eb16121cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message object\n",
    "response = model.invoke([\n",
    "    HummanMessage(\"What is machine learning?\")\n",
    "])\n",
    "\n",
    "# String shortcut\n",
    "response = model.invoke(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48103699-387f-4b0e-9cd7-d4d548830059",
   "metadata": {},
   "source": [
    "### AIMessage\n",
    "An AIMessage represents the output of a model invocation. They can include multimodal data, tool calls, and provider-specific meta data that you can later access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e17009-be88-40f0-9302-e44aa55e18d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"Explain AI\")\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc347c-46c8-4a39-8589-47ba2b4b45d5",
   "metadata": {},
   "source": [
    "**AIMessage** objects are returnes by the model when calling it, which contains all of the associated metadata in the response.\n",
    "\n",
    "Providers weigh/contextualize types fo messages differently, which means it's sometimes helpful to manually create a new AIMessage object and insert it into the message history as if it came from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b49c1ca8-9bcc-4bc3-a34b-16c2792defc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg, # Insert as if it came from the model\n",
    "    HumanMessage(\"Great! What's 2 + 2?\")\n",
    "]\n",
    "\n",
    "reponse = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f10cb6-f405-452f-a129-79e035b6273f",
   "metadata": {},
   "source": [
    "## Message content\n",
    "You can think of a message's content as the payload of data that gets sent to the model. Messages have a **content** attribute that is loosely-typed, supporting strings and lists of untyped objects (e.g. dictionaries). This allows support for provider-native structures directly in LangChain chat models, such as multimodal content and other data.\n",
    "\n",
    "LangChain chat models accept message content in the `content` attribute, this may contain either:\n",
    "- A string\n",
    "- A list of content blocks in a provider-native format\n",
    "- a iist of LangChain's standard content blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eba73c9-c080-401b-ab3d-36c8099d581b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for HumanMessage\ncontent.str\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\ncontent.list[union[str,dict[any,any]]]\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m human_message \u001b[38;5;241m=\u001b[39m HumanMessage(content \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, how are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      9\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://example.com/image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     10\u001b[0m ])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# List of standard content blocks\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m human_message \u001b[38;5;241m=\u001b[39m \u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_block\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello, how are you?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://example.com/image.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m human_message\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/langchain_core/messages/human.py:60\u001b[0m, in \u001b[0;36mHumanMessage.__init__\u001b[0;34m(self, content, content_blocks, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     56\u001b[0m         content\u001b[38;5;241m=\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr | list[str | dict]\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_blocks),\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/langchain_core/messages/base.py:179\u001b[0m, in \u001b[0;36mBaseMessage.__init__\u001b[0;34m(self, content, content_blocks, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(content\u001b[38;5;241m=\u001b[39mcontent_blocks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/langchain_core/load/serializable.py:116\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    255\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for HumanMessage\ncontent.str\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\ncontent.list[union[str,dict[any,any]]]\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "# String content\n",
    "human_message = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "# Provider-native format (e.g. OpenAI)\n",
    "human_message = HumanMessage(content = [\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image_url\", \"image_url\": \"https://example.com/image.jpg\"}\n",
    "])\n",
    "\n",
    "# List of standard content blocks\n",
    "human_message = HumanMessage(content_block = [\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image\", \"url\": \"https://example.com/image.jpg\"}\n",
    "])\n",
    "\n",
    "human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dd65a-43d9-4f84-8c40-92ee6fadba53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
